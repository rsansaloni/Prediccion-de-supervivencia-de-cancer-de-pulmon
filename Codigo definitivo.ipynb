{"cells":[{"cell_type":"markdown","source":["# 1. Carpetas base e instalación de librerías"],"metadata":{"id":"VO-1HrWes5Fz"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"i57Sj5KZpJ4T","executionInfo":{"status":"ok","timestamp":1697549784173,"user_tz":-180,"elapsed":13,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"outputs":[],"source":["DATASET_FOLDER = '/content/drive/MyDrive/Lung_Dataset'\n","IMAGES_FOLDER = '/content/drive/MyDrive/Lung_Dataset/Imagenes'\n","IMAGES_NRRD_FOLDER = '/content/drive/MyDrive/Lung_Dataset/Imagenes_NRRD'\n","IMAGES_PRED_NRRD_FOLDER = '/content/drive/MyDrive/Lung_Dataset/Imagenes_Pred_NRRD'\n","SEGMENTATION_CODE_FOLDER = '/content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion'\n","MODEL_FOLDER = '/content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Model'"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install SimpleITK\n","!pip install -r '/content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt'\n","!pip install pydicom\n","!pip install pyplastimatch\n","!pip install dcm2niix\n","!pip install pydicom_seg\n","!pip install dicom2nifti\n","!pip install pyradiomics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"93AyNnNEgm3J","executionInfo":{"status":"ok","timestamp":1697549906199,"user_tz":-180,"elapsed":122037,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}},"outputId":"cfdffda5-74f0-4880-f3a0-c7a5b7d0fa2b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Collecting SimpleITK\n","  Downloading SimpleITK-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: SimpleITK\n","Successfully installed SimpleITK-2.3.0\n","Requirement already satisfied: notebook>=6.1.4 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (6.5.5)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 2)) (1.23.5)\n","Requirement already satisfied: pandas>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 3)) (1.5.3)\n","Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 4)) (4.8.0.76)\n","Requirement already satisfied: keras>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 5)) (2.13.1)\n","Requirement already satisfied: pillow>=8.0.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 6)) (9.4.0)\n","Collecting pydicom>=1.3.0 (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 7))\n","  Downloading pydicom-2.4.3-py3-none-any.whl (1.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pywavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 8)) (1.4.1)\n","Requirement already satisfied: ipywidgets>=7.5.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (7.7.1)\n","Requirement already satisfied: scikit-image>=0.17.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 10)) (0.19.3)\n","Requirement already satisfied: scikit-learn>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 11)) (1.2.2)\n","Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 12)) (1.11.3)\n","Requirement already satisfied: seaborn>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (0.12.2)\n","Requirement already satisfied: setuptools>=50.3.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 14)) (67.7.2)\n","Requirement already satisfied: simpleitk>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 15)) (2.3.0)\n","Collecting statannot>=0.2.3 (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 16))\n","  Downloading statannot-0.2.3-py3-none-any.whl (10 kB)\n","Requirement already satisfied: statsmodels>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 17)) (0.14.0)\n","Requirement already satisfied: tensorflow>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.13.0)\n","Requirement already satisfied: tqdm>=4.50.2 in /usr/local/lib/python3.10/dist-packages (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 19)) (4.66.1)\n","Collecting xlrd==1.2.0 (from -r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 20))\n","  Downloading xlrd-1.2.0-py2.py3-none-any.whl (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (3.1.2)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (6.3.2)\n","Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (23.2.1)\n","Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (23.1.0)\n","Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (5.7.1)\n","Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (5.4.0)\n","Requirement already satisfied: jupyter-client<8,>=5.3.4 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (6.1.12)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (5.9.2)\n","Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (6.5.4)\n","Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.5.8)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (5.5.6)\n","Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.8.2)\n","Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.17.1)\n","Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.17.1)\n","Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.0.0)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 3)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 3)) (2023.3.post1)\n","Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (3.6.6)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (7.34.0)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (3.0.9)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 10)) (3.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 10)) (2.31.5)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 10)) (2023.9.26)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.17.2->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 10)) (23.2)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 11)) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.23.2->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 11)) (3.2.0)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn>=0.11.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (3.7.1)\n","Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12.0->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 17)) (0.5.3)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (23.5.26)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.59.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.9.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (16.0.6)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.3.0)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.20.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.16.0)\n","Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.13.0)\n","Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.13.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.3.0)\n","Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.15.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.34.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.41.2)\n","Collecting jedi>=0.16 (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9))\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (3.0.39)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (4.8.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (3.11.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn>=0.11.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 13)) (3.1.1)\n","Requirement already satisfied: jupyter-server>=1.8 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.24.0)\n","Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.2.3)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (4.9.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (4.11.2)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (6.1.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.7.1)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.4)\n","Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.2.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (2.1.3)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.8.4)\n","Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.8.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.5.0)\n","Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.2.1)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (2.18.1)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (4.19.1)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.17.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.31.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.7.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.0.0)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.10/dist-packages (from terminado>=0.8.3->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.7.0)\n","Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (21.2.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (5.3.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (1.3.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (0.8.3)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (2023.7.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.30.2)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.10.4)\n","Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (3.7.1)\n","Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.6.4)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets>=7.5.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 9)) (0.2.8)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (2023.7.22)\n","Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.16.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (2.5)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert>=5->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (0.5.1)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (1.1.3)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=6.1.4->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 1)) (2.21)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (0.5.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow>=2.4.1->-r /content/drive/MyDrive/Codigo_TFM/Lung/Codigo_segunda_entrega/Segmentacion/requirements.txt (line 18)) (3.2.2)\n","Installing collected packages: xlrd, statannot, pydicom, jedi\n","  Attempting uninstall: xlrd\n","    Found existing installation: xlrd 2.0.1\n","    Uninstalling xlrd-2.0.1:\n","      Successfully uninstalled xlrd-2.0.1\n","Successfully installed jedi-0.19.1 pydicom-2.4.3 statannot-0.2.3 xlrd-1.2.0\n","Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.3)\n","Collecting pyplastimatch\n","  Downloading pyplastimatch-0.4.3-py3-none-any.whl (13 kB)\n","Collecting itk (from pyplastimatch)\n","  Downloading itk-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (8.3 kB)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (3.7.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (1.23.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (1.5.3)\n","Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (2.4.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (2.31.0)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (0.19.3)\n","Requirement already satisfied: SimpleITK in /usr/local/lib/python3.10/dist-packages (from pyplastimatch) (2.3.0)\n","Collecting itk-core==5.3.0 (from itk->pyplastimatch)\n","  Downloading itk_core-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (81.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-numerics==5.3.0 (from itk->pyplastimatch)\n","  Downloading itk_numerics-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (58.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-io==5.3.0 (from itk->pyplastimatch)\n","  Downloading itk_io-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (25.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.6/25.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-filtering==5.3.0 (from itk->pyplastimatch)\n","  Downloading itk_filtering-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (73.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-registration==5.3.0 (from itk->pyplastimatch)\n","  Downloading itk_registration-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (26.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting itk-segmentation==5.3.0 (from itk->pyplastimatch)\n","  Downloading itk_segmentation-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (16.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (1.1.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (4.43.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (23.2)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->pyplastimatch) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pyplastimatch) (2023.3.post1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyplastimatch) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyplastimatch) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyplastimatch) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyplastimatch) (2023.7.22)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->pyplastimatch) (1.11.3)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->pyplastimatch) (3.1)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->pyplastimatch) (2.31.5)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->pyplastimatch) (2023.9.26)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->pyplastimatch) (1.4.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->pyplastimatch) (1.16.0)\n","Installing collected packages: itk-core, itk-numerics, itk-io, itk-filtering, itk-segmentation, itk-registration, itk, pyplastimatch\n","Successfully installed itk-5.3.0 itk-core-5.3.0 itk-filtering-5.3.0 itk-io-5.3.0 itk-numerics-5.3.0 itk-registration-5.3.0 itk-segmentation-5.3.0 pyplastimatch-0.4.3\n","Collecting dcm2niix\n","  Downloading dcm2niix-1.0.20220715.tar.gz (451 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.4/451.4 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting miutil[web] (from dcm2niix)\n","  Downloading miutil-0.12.0-py3-none-any.whl (18 kB)\n","Requirement already satisfied: tqdm>=4.40.0 in /usr/local/lib/python3.10/dist-packages (from miutil[web]->dcm2niix) (4.66.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from miutil[web]->dcm2niix) (2.31.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (3.3.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (2.0.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->miutil[web]->dcm2niix) (2023.7.22)\n","Building wheels for collected packages: dcm2niix\n","  Building wheel for dcm2niix (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dcm2niix: filename=dcm2niix-1.0.20220715-cp310-cp310-linux_x86_64.whl size=559552 sha256=68f1a3c5388be836b6c8a61cba4b4595e6ed08074314667f49170cba16115b8b\n","  Stored in directory: /root/.cache/pip/wheels/88/8d/9b/5ea20c0451a1acddef585757be7dfec121ee076e58503b267c\n","Successfully built dcm2niix\n","Installing collected packages: miutil, dcm2niix\n","Successfully installed dcm2niix-1.0.20220715 miutil-0.12.0\n","Collecting pydicom_seg\n","  Downloading pydicom_seg-0.4.1-py3-none-any.whl (27 kB)\n","Requirement already satisfied: SimpleITK>1.2.4 in /usr/local/lib/python3.10/dist-packages (from pydicom_seg) (2.3.0)\n","Collecting jsonschema<4.0.0,>=3.2.0 (from pydicom_seg)\n","  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from pydicom_seg) (1.23.5)\n","Requirement already satisfied: pydicom>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from pydicom_seg) (2.4.3)\n","Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom_seg) (23.1.0)\n","Collecting pyrsistent>=0.14.0 (from jsonschema<4.0.0,>=3.2.0->pydicom_seg)\n","  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom_seg) (67.7.2)\n","Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.0.0,>=3.2.0->pydicom_seg) (1.16.0)\n","Installing collected packages: pyrsistent, jsonschema, pydicom_seg\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.19.1\n","    Uninstalling jsonschema-4.19.1:\n","      Successfully uninstalled jsonschema-4.19.1\n","Successfully installed jsonschema-3.2.0 pydicom_seg-0.4.1 pyrsistent-0.19.3\n","Collecting dicom2nifti\n","  Downloading dicom2nifti-2.4.8-py3-none-any.whl (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (4.0.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (1.11.3)\n","Requirement already satisfied: pydicom>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from dicom2nifti) (2.4.3)\n","Collecting python-gdcm (from dicom2nifti)\n","  Downloading python_gdcm-3.0.22-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (23.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->dicom2nifti) (67.7.2)\n","Installing collected packages: python-gdcm, dicom2nifti\n","Successfully installed dicom2nifti-2.4.8 python-gdcm-3.0.22\n","Collecting pyradiomics\n","  Downloading pyradiomics-3.1.0.tar.gz (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Discarding \u001b[4;34mhttps://files.pythonhosted.org/packages/03/c1/20fc2c50ab1e3304da36d866042a1905a2b05a1431ece35448ab6b4578f2/pyradiomics-3.1.0.tar.gz (from https://pypi.org/simple/pyradiomics/)\u001b[0m: \u001b[33mRequested pyradiomics from https://files.pythonhosted.org/packages/03/c1/20fc2c50ab1e3304da36d866042a1905a2b05a1431ece35448ab6b4578f2/pyradiomics-3.1.0.tar.gz has inconsistent version: expected '3.1.0', but metadata has '3.0.1a1'\u001b[0m\n","  Downloading pyradiomics-3.0.1.tar.gz (34.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.10/dist-packages (from pyradiomics) (1.23.5)\n","Requirement already satisfied: SimpleITK>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from pyradiomics) (2.3.0)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pyradiomics) (1.4.1)\n","Collecting pykwalify>=1.6.0 (from pyradiomics)\n","  Downloading pykwalify-1.8.0-py2.py3-none-any.whl (24 kB)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from pyradiomics) (1.16.0)\n","Collecting docopt>=0.6.2 (from pykwalify>=1.6.0->pyradiomics)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from pykwalify>=1.6.0->pyradiomics) (2.8.2)\n","Collecting ruamel.yaml>=0.16.0 (from pykwalify>=1.6.0->pyradiomics)\n","  Downloading ruamel.yaml-0.17.35-py3-none-any.whl (112 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.9/112.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.16.0->pykwalify>=1.6.0->pyradiomics)\n","  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: pyradiomics, docopt\n","  Building wheel for pyradiomics (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyradiomics: filename=pyradiomics-3.0.1-cp310-cp310-linux_x86_64.whl size=169715 sha256=04936d7a3ca3e65e7a7e8bb0a2f0551e9674625a2a39dda729dd5a79a48ede8a\n","  Stored in directory: /root/.cache/pip/wheels/91/c5/13/c5fd4c5ad3edf4062bb3855bd66fad25871c9c6dc0b3fda544\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=629817b72abb18f4f3a058b84e5f6db63083ae011b927921435ba89d57439a13\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built pyradiomics docopt\n","Installing collected packages: docopt, ruamel.yaml.clib, ruamel.yaml, pykwalify, pyradiomics\n","Successfully installed docopt-0.6.2 pykwalify-1.8.0 pyradiomics-3.0.1 ruamel.yaml-0.17.35 ruamel.yaml.clib-0.2.8\n"]}]},{"cell_type":"markdown","source":["# 2. Importación de módulos"],"metadata":{"id":"YBCIurbos6YO"}},{"cell_type":"code","execution_count":14,"metadata":{"id":"2_hb3vumJEl1","executionInfo":{"status":"ok","timestamp":1697549979143,"user_tz":-180,"elapsed":8,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import os\n","import matplotlib.pyplot as plt\n","import gzip\n","import cv2\n","import csv\n","from PIL import Image\n","\n","from radiomics import featureextractor\n","import radiomics\n","from radiomics import firstorder, glcm, glrlm, glszm, gldm, ngtdm, shape, shape2D\n","import SimpleITK as sitk\n","\n","import pywt\n","import pydicom\n","from pydicom import dcmread\n","import pyplastimatch\n","import dcm2niix\n","import pydicom_seg\n","import dicom2nifti\n","\n","from sklearn.model_selection import train_test_split, cross_validate, KFold, cross_val_predict, cross_val_score\n","from sklearn import metrics\n","from sklearn.decomposition import PCA\n","\n","from sklearn import preprocessing\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras.models import Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, Dropout, LSTM\n","from tensorflow.keras import layers, models\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.covariance import EllipticEnvelope\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from keras.utils import plot_model\n","\n","import random\n","import sklearn\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","\n","import sys\n","sys.path.insert(0,SEGMENTATION_CODE_FOLDER)\n","from TheDuneAI import ContourPilot as cp"]},{"cell_type":"markdown","source":["# 3. Funciones para preprocesar los datos"],"metadata":{"id":"B7BjOeaZGG8z"}},{"cell_type":"markdown","source":["## 3.1 Para los datos genómicos"],"metadata":{"id":"RCOa44AyJP1Y"}},{"cell_type":"code","source":["def eliminaOutliers(df):\n","\t# Usamos el algoritmo de envolvente elíptica para detectar los outliers. Eliminaremos un 10% de los valores anómalos\n","\tenveliptica = EllipticEnvelope(contamination=0.10, support_fraction=0.8, random_state=42)\n","\tdf_outliers = enveliptica.fit_predict(df)\n","\tdf = df[df_outliers==1]\n","\treturn df\n","\n","def eliminaAtributosCorrelacionados(df):\n","\tmatriz_corr = df.corr().abs()\n","\ttriang_superior = matriz_corr.where(np.triu(np.ones(matriz_corr.shape), k=1).astype(bool))\n","\tcolumnas_correlacionadas = [column for column in triang_superior.columns if any(triang_superior[column] > 0.90)]\n","\tdf.drop(columnas_correlacionadas, axis=1, inplace=True)\n","\treturn df\n","\n","def aplicaPCA(df):\n","\tindex_names = df.index.tolist()\n","\tdata_genoma = df.values\n","\tpca = PCA(n_components=0.98)\n","\tgenoma_pca = pca.fit_transform(data_genoma)\n","\tpca_df = pd.DataFrame(data=genoma_pca, index=index_names)\n","\n","\treturn pca_df"],"metadata":{"id":"24me20AGGlcA","executionInfo":{"status":"ok","timestamp":1697549913314,"user_tz":-180,"elapsed":68,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def preprocesaDatosGenomicos(path_dataset):\n","\tprint(\"Preprocesando datos genómicos\")\n","\tpath_genoma_txt = os.path.join(path_dataset, 'GSE103584_R01_NSCLC_RNAseq.txt.gz')\n","\tdf_genoma = pd.read_csv(gzip.open(path_genoma_txt), sep='\\t', index_col=0).fillna(0)\n","\tdf_genoma = (df_genoma.T)\n","\t#---------- PREPROCESADO DE LOS DATOS ----------#\n","\t#---------- 1. Estimación de valores ausentes ----------#\n","\t#Sustituimos los valores ausentes por la media\n","\tdf_genoma.fillna(df_genoma.mean(), inplace=True)\n","\t#---------- 2. Normalización ----------#\n","\t#Normalizamos los datos\n","\tscaler = preprocessing.MinMaxScaler()\n","\tpacientes_id = df_genoma.index.values\n","\tdf_genoma = pd.DataFrame(scaler.fit_transform(df_genoma),columns = df_genoma.columns, index = pacientes_id)\n","\n","\t#---------- 3. Reducción de dimensionalidad ----------#\n","\t#Reducimos el número de columnas para evitar descompensar el dataset final\n","\tdisplay(df_genoma)\n","\tdf_genoma = aplicaPCA(df_genoma)\n","\n","\t#---------- 4. Tratamiento de outliers ------------#\n","\tdisplay(df_genoma)\n","\tdf_genoma = eliminaOutliers(df_genoma)\n","\tdisplay(df_genoma)\n","\treturn df_genoma"],"metadata":{"id":"yrm-smkYLe06","executionInfo":{"status":"ok","timestamp":1697549913315,"user_tz":-180,"elapsed":57,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## 3.2 Para los los datos clínicos"],"metadata":{"id":"hvdwPtHmJH95"}},{"cell_type":"code","source":["def preprocesarFechas (df_pacientes):\n","\t#Para las fechas eliminamos los labels Not Collected y las convertimos a valor numérico timestamp\n","\t#Para Date of Recurrence\n","\tdf_pacientes[\"Date of Recurrence\"].replace(\"Not Collected\",np.nan, inplace=True)\n","\tdf_pacientes[\"Date of Recurrence\"].fillna(\"5/5/1995\", inplace=True)\n","\tdf_pacientes[\"Date of Recurrence\"] = pd.to_datetime(df_pacientes['Date of Recurrence']).astype(int)\n","\n","\t#Para CT Date\n","\tdf_pacientes[\"CT Date\"].replace(\"Not Collected\",np.nan, inplace=True)\n","\tdf_pacientes[\"CT Date\"].fillna(\"5/5/1995\", inplace=True)\n","\tdf_pacientes[\"CT Date\"] = pd.to_datetime(df_pacientes['CT Date']).astype(int)\n","\n","\t#Para PET Date\n","\tdf_pacientes[\"PET Date\"].replace(\"Not Collected\",np.nan, inplace=True)\n","\tdf_pacientes[\"PET Date\"].fillna(\"5/5/1995\", inplace=True)\n","\tdf_pacientes[\"PET Date\"] = pd.to_datetime(df_pacientes['PET Date']).astype(int)\n","\n","\t#Para Date of Death\n","\tdf_pacientes[\"Date of Death\"].replace(\"Not Collected\",np.nan, inplace=True)\n","\tdf_pacientes[\"Date of Death\"].fillna(\"5/5/1995\", inplace=True)\n","\tdf_pacientes[\"Date of Death\"] = pd.to_datetime(df_pacientes['Date of Death']).astype(int)\n","\n","\t#Para Date of Last Known Alive\n","\tdf_pacientes[\"Date of Last Known Alive\"].replace(\"Not Collected\",np.nan, inplace=True)\n","\tdf_pacientes[\"Date of Last Known Alive\"].fillna(\"5/5/1995\", inplace=True)\n","\tdf_pacientes[\"Date of Last Known Alive\"] = pd.to_datetime(df_pacientes['Date of Last Known Alive']).astype(int)\n","\treturn df_pacientes\n","\n","def preprocesaDatosClinicos(path_dataset):\n","\tprint(\"Preprocesando datos clínicos\")\n","\tpath_csv = os.path.join(path_dataset, 'NSCLCR01Radiogenomic_DATA_LABELS_2018-05-22_1500-shifted.csv')\n","\tdf_pacientes = pd.read_csv(path_csv)\n","\tdf_pacientes.set_index('Case ID', inplace=True)\n","\tdisplay(df_pacientes)\n","\n","\t#----------PREPROCESADO DE LOS DATOS----------#\n","\t#Los valores númericos que estan en String los convertimos a números\n","\tdf_pacientes[\"Weight (lbs)\"] = df_pacientes[\"Weight (lbs)\"].apply(pd.to_numeric, errors = 'coerce')\n","\tdf_pacientes[\"Pack Years\"] = df_pacientes[\"Pack Years\"].apply(pd.to_numeric, errors = 'coerce')\n","\n","\t#Preprocesamos las fechas\n","\tdf_pacientes = preprocesarFechas(df_pacientes)\n","\n","\t#3.Codificamos las variables categóricas en números y normalizamos las variables numéricas\n","\tfor column in df_pacientes:\n","\t\tif (df_pacientes[column].dtype == np.float64) or (df_pacientes[column].dtype == np.int64):\n","\t\t\t#Sustituimos los valores NaN (valores ausentes) por la media\n","\t\t\tdf_pacientes[column].fillna(df_pacientes[column].mean(), inplace=True)\n","\t\t\tdf_pacientes[column] = (df_pacientes[column] - df_pacientes[column].min())/(df_pacientes[column].max() - df_pacientes[column].min())\n","\t\telse:\n","\t\t\tdf_pacientes = pd.get_dummies(data=df_pacientes, columns=[column], prefix=[column], prefix_sep= \" | \")\n","\t#Elimanos atributos correlacionados\n","\tdf_pacientes = eliminaAtributosCorrelacionados(df_pacientes)\n","\t#Relacionamos las datos genómicos con los clínicos con un join\n","\tdf_pacientes.fillna(df_pacientes.mean(), inplace=True)\n","\tdisplay(df_pacientes)\n","\n","\treturn df_pacientes"],"metadata":{"id":"THv1yszzJc_7","executionInfo":{"status":"ok","timestamp":1697549913315,"user_tz":-180,"elapsed":55,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## 3.3. Para los datos radiómicos"],"metadata":{"id":"4tyEr1bEJrNI"}},{"cell_type":"markdown","source":["### 3.3.1 Funciones para guardar las imágenes en NRRD"],"metadata":{"id":"UIs-4LcbJ_In"}},{"cell_type":"code","source":["def contiene_valores(group):\n","    return ('CT' in group['Modality'].values) and ('SEG' in group['Modality'].values)\n","\n","def obtenPathCorrecto(path):\n","\tstring_nslsc = r\".\\NSCLC Radiogenomics\" + \"\\\\\"\n","\tpath_correcto = path.replace(string_nslsc, '').replace(\"\\\\\",\"/\")\n","\treturn path_correcto\n","\n","def escribirCTNRRD(subject_id, path_nttd, path_ct_original):\n","    path_ct_original = os.path.join(IMAGES_FOLDER, path_ct_original)\n","    path_subject_nrrd = os.path.join(path_nttd, subject_id)\n","\n","    if not os.path.exists(path_subject_nrrd):\n","        os.makedirs(path_subject_nrrd)\n","\n","    path_ct_nrrd = os.path.join(path_subject_nrrd, \"image.nrrd\")\n","    if not os.path.exists(path_ct_nrrd):\n","        reader = sitk.ImageSeriesReader()\n","        dicom_names = reader.GetGDCMSeriesFileNames(path_ct_original)\n","        reader.SetFileNames(dicom_names)\n","        dicom_image = reader.Execute()\n","        sitk.WriteImage(dicom_image, path_ct_nrrd)\n","\n","def escribirSegmentacionNRRD(subject_id, path_nttd, path_seg_original):\n","    path_seg_original = os.path.join(IMAGES_FOLDER, path_seg_original)\n","    archivo_seg = os.listdir(path_seg_original)[0]\n","    path_seg_original = os.path.join(path_seg_original, archivo_seg)\n","\n","    path_subject_nrrd = os.path.join(path_nttd, subject_id)\n","    if not os.path.exists(path_subject_nrrd):\n","        os.makedirs(path_subject_nrrd)\n","\n","    path_seg_nrrd = os.path.join(path_subject_nrrd, \"mask.nrrd\")\n","    if not os.path.exists(path_seg_nrrd):\n","        dcm_imagen_seg = pydicom.dcmread(path_seg_original)\n","\n","        reader = pydicom_seg.MultiClassReader()\n","        result = reader.read(dcm_imagen_seg)\n","\n","        image_data = result.data\n","        image = result.image\n","        sitk.WriteImage(image, path_seg_nrrd, True)\n","\n","def guardarImagenesConSegmentacionNRRD(path_dataset):\n","\tpath_imagenes = os.path.join(path_dataset, 'Imagenes')\n","\n","\tdf_metadata = pd.read_csv(os.path.join(path_dataset, 'metadata.csv'))\n","\tdf_metadata = df_metadata.reset_index()\n","\n","\tfor subject_id in df_metadata['Subject ID'].unique():\n","\t\tdf_filtered_by_subject = df_metadata[df_metadata['Subject ID'] == subject_id]\n","\t\tdf_grouped_by_subject = df_filtered_by_subject.groupby('Subject ID')\n","\n","\t\tfiltered = df_grouped_by_subject.filter(contiene_valores)\n","\t\tif not filtered.empty:\n","\t\t\tprint(\"------ \" + subject_id + \" ------\")\n","\t\t\t#Filtramos el dataframe para solo obtener las filas que sean segmentaciones\n","\t\t\trow_where_seg = df_filtered_by_subject[df_filtered_by_subject['Modality'] == 'SEG']\n","            #Obtenemos el valor del path a esa segmentacion\n","\t\t\tpath_mask = row_where_seg['File Location'].values[0]\n","\t\t\tpath_carpeta_general = path_mask.rsplit('\\\\', 1)[0]\n","\n","            #Obtenemos el path a la imagen ct de la segmentación\n","\t\t\trows_where_ct = df_filtered_by_subject[df_filtered_by_subject['Modality'] == 'CT']\n","\t\t\trow_where_ct = rows_where_ct[rows_where_ct['File Location'].str.startswith(path_carpeta_general)]\n","\t\t\tpath_ct = row_where_ct['File Location'].values[0]\n","\n","\t\t\tescribirCTNRRD(subject_id, IMAGES_NRRD_FOLDER, obtenPathCorrecto(path_ct))\n","\t\t\tescribirSegmentacionNRRD(subject_id, IMAGES_NRRD_FOLDER, obtenPathCorrecto(path_mask))\n","\n","def guardarImagenesSinSegmentacionNRRD(path_dataset):\n","\tpath_imagenes = os.path.join(path_dataset, 'Imagenes')\n","\n","\tdf_metadata = pd.read_csv(os.path.join(path_dataset, 'metadata.csv'))\n","\tdf_metadata = df_metadata.reset_index()\n","\n","\tfor subject_id in df_metadata['Subject ID'].unique():\n","\t\tdf_filtered_by_subject = df_metadata[df_metadata['Subject ID'] == subject_id]\n","\t\tdf_grouped_by_subject = df_filtered_by_subject.groupby('Subject ID')\n","\n","\t\tfiltered = df_grouped_by_subject.filter(contiene_valores)\n","\t\tif filtered.empty:\n","\t\t\tprint(\"NOT SEG ------ \" + subject_id + \" ------\")\n","\n","\t\t\trows_where_ct = df_filtered_by_subject[df_filtered_by_subject['Modality'] == 'CT']\n","\t\t\trows_with_no_pet = rows_where_ct[~rows_where_ct['File Location'].str.contains('PET')]\n","\t\t\tmax_num_files = rows_with_no_pet['Number of Images'].max()\n","\t\t\trow_max_num_files = rows_with_no_pet[rows_with_no_pet['Number of Images'] == max_num_files]\n","\t\t\tnum_rows = row_max_num_files.shape\n","\t\t\tnum_rows, num_columns = row_max_num_files.shape\n","\t\t\tif num_rows > 0:\n","\t\t\t\tpath_ct = row_max_num_files['File Location'].values[0]\n","\t\t\t\tescribirCTNRRD(subject_id, IMAGES_PRED_NRRD_FOLDER, obtenPathCorrecto(path_ct))\n"],"metadata":{"id":"He--nsNIJ76Y","executionInfo":{"status":"ok","timestamp":1697549913316,"user_tz":-180,"elapsed":53,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### 3.3.2 Funciones para predecir las segmentaciones restantes"],"metadata":{"id":"EMYhtfUXKTiU"}},{"cell_type":"code","source":["def predecirSegmentacionNRRD(path_dataset):\n","\tpath_imagenes = os.path.join(path_dataset, 'Imagenes')\n","\tpath_modelo = os.path.join(SEGMENTATION_CODE_FOLDER, 'Modelo')\n","\tmodel = cp(path_modelo,IMAGES_PRED_NRRD_FOLDER,IMAGES_PRED_NRRD_FOLDER,verbosity=True)\n","\tmodel.segment()\n","\n","def guardarImagenesYPredecirSegmentacionNRRD(path_dataset):\n","\tguardarImagenesSinSegmentacionNRRD(path_dataset)\n","\tguardarImagenesConSegmentacionNRRD(path_dataset)\n","\tpredecirSegmentacionNRRD(path_dataset)"],"metadata":{"id":"EGgTT1mcKZER","executionInfo":{"status":"ok","timestamp":1697549913316,"user_tz":-180,"elapsed":22,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### 3.3.3 Funciones para extrar y guardar los datos radiómicos"],"metadata":{"id":"c5w56kK9K7uP"}},{"cell_type":"code","source":["def extraerDatosRadiomicosImagen(extractor, path_nrrd):\n","    path_nrrd_ct = os.path.join(path_nrrd, 'image.nrrd')\n","    path_nrrd_seg = os.path.join(path_nrrd, 'mask.nrrd')\n","\n","    image_nrrd_ct = sitk.ReadImage(path_nrrd_ct)\n","    image_nrrd_seg = sitk.ReadImage(path_nrrd_seg)\n","    try:\n","        firstOrderFeatures = firstorder.RadiomicsFirstOrder(image_nrrd_ct, image_nrrd_seg)\n","        glcmFeatures = glcm.RadiomicsGLCM(image_nrrd_ct, image_nrrd_seg)\n","        glrlmFeatures = glrlm.RadiomicsGLRLM(image_nrrd_ct, image_nrrd_seg)\n","        ngtdmFeatures = ngtdm.RadiomicsNGTDM(image_nrrd_ct, image_nrrd_seg)\n","        gldmFeatures = gldm.RadiomicsGLDM(image_nrrd_ct, image_nrrd_seg)\n","    except Exception as e:\n","        return np.empty(0)\n","    else:\n","        firstOrderFeatures = np.array([v for _, v in firstOrderFeatures.execute().items()])\n","        glcmFeatures = np.array([v for _, v in glcmFeatures.execute().items()])\n","        glrlmFeatures = np.array([v for _, v in glrlmFeatures.execute().items()])\n","        ngtdmFeatures = np.array([v for _, v in ngtdmFeatures.execute().items()])\n","        gldmFeatures = np.array([v for _, v in gldmFeatures.execute().items()])\n","        caract_radiomics = np.hstack((firstOrderFeatures, glcmFeatures, glrlmFeatures, ngtdmFeatures, gldmFeatures))\n","        return caract_radiomics\n","\n","def extraerDatosRadiomicosCarpeta(path_carpeta, path_caract_radiomicas_parciales):\n","    lista_caract_radiomicas = {}\n","    lista_sujetos = {}\n","    if os.path.exists(path_caract_radiomicas_parciales):\n","        df_radiomicas_parciales = pd.read_csv(path_caract_radiomicas_parciales, index_col=0, header=0)\n","        for index, row in df_radiomicas_parciales.iterrows():\n","            lista_caract_radiomicas[index] = row.values\n","        lista_sujetos = df_radiomicas_parciales.index.tolist()\n","\n","    extractor = featureextractor.RadiomicsFeatureExtractor()\n","\n","    for nombre_subcarpeta in os.listdir(path_carpeta):\n","        if nombre_subcarpeta not in lista_sujetos:\n","            print(\"   paciente \" + nombre_subcarpeta)\n","            path_subcarpeta= os.path.join(path_carpeta, nombre_subcarpeta)\n","            datos_radiomicos_imagen = extraerDatosRadiomicosImagen(extractor, path_subcarpeta)\n","\n","            if datos_radiomicos_imagen.size != 0:\n","                lista_caract_radiomicas[nombre_subcarpeta] = datos_radiomicos_imagen\n","                df_radiomicas_parciales = pd.DataFrame.from_dict(lista_caract_radiomicas, orient='index')\n","                df_radiomicas_parciales.fillna(0, inplace=True)\n","                df_radiomicas_parciales.index.name='Case ID'\n","                df_radiomicas_parciales.to_csv(path_caract_radiomicas_parciales, index=True, header=True)\n","    return lista_caract_radiomicas\n","\n","def procesaDatosRadiomicos(lista_caract_radiomicas):\n","    df_imagenes = pd.DataFrame.from_dict(lista_caract_radiomicas, orient='index')\n","    df_imagenes.fillna(0, inplace=True)\n","    scaler = preprocessing.MinMaxScaler()\n","    pacientes_id = df_imagenes.index.values\n","    caract_imagenes = pd.DataFrame(scaler.fit_transform(df_imagenes),columns = df_imagenes.columns, index = pacientes_id)\n","    caract_imagenes.index.name='Case ID'\n","    return caract_imagenes\n","\n","def extraerDatosRadiomicos(path_dataset):\n","    print(\"Extrayendo datos radiómicos...\")\n","\n","    path_caract_radiomicas_parciales = os.path.join(path_dataset, 'Caracteristicas_extraidas/datos_radiomicos_parciales.csv')\n","\n","    lista_caract_radiomicas_seg_orig = extraerDatosRadiomicosCarpeta(IMAGES_NRRD_FOLDER, path_caract_radiomicas_parciales)\n","    lista_caract_radiomicas = extraerDatosRadiomicosCarpeta(IMAGES_PRED_NRRD_FOLDER, path_caract_radiomicas_parciales)\n","\n","    return procesaDatosRadiomicos(lista_caract_radiomicas)\n"],"metadata":{"id":"04-2W2uvLBpk","executionInfo":{"status":"ok","timestamp":1697549913316,"user_tz":-180,"elapsed":18,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# 4. Extracción de las características"],"metadata":{"id":"GdKaWyW8XWYM"}},{"cell_type":"markdown","source":["## 4.1 Guardar características"],"metadata":{"id":"EcBZvA07l5N5"}},{"cell_type":"code","source":["def preprocesaYGuardaCaracteristicas(path_dataset):\n","    #Si las características de los datos clínicos no habían sido extraidas y guardadas, las guardamos\n","    path_caract_clinicas = os.path.join(path_dataset, 'Caracteristicas_extraidas/datos_clinicos.csv')\n","    if not os.path.isfile(path_caract_clinicas):\n","        caract_clinicas = preprocesaDatosClinicos(path_dataset)\n","        caract_clinicas.to_csv(path_caract_clinicas, index=True, header=True)\n","\n","    #Si las características de los datos genómicos no habían sido extraidas y guardadas, las guardamos\n","    path_caract_genomicas = os.path.join(path_dataset, 'Caracteristicas_extraidas/datos_genomicos.csv')\n","    if not os.path.isfile(path_caract_genomicas):\n","        caract_genomicas = preprocesaDatosGenomicos(path_dataset)\n","        caract_genomicas.to_csv(path_caract_genomicas, index=True, header=True)\n","\n","    #Si las características de los datos radiómicos no habían sido extraidas y guardadas, las guardamos\n","    path_caract_radiomicas = os.path.join(path_dataset, 'Caracteristicas_extraidas/datos_radiomicos.csv')\n","    if not os.path.isfile(path_caract_radiomicas):\n","        caract_radiomicas = extraerDatosRadiomicos(path_dataset)\n","        caract_radiomicas.to_csv(path_caract_radiomicas, index=True, header=True)"],"metadata":{"id":"nHLwmhpJXn9M","executionInfo":{"status":"ok","timestamp":1697549913317,"user_tz":-180,"elapsed":17,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## 4.2 Extraer características"],"metadata":{"id":"r_84VNaul-mp"}},{"cell_type":"code","source":["def extraeCaracteristicasCompletas(path_caract_1, path_caract_2, path_caract_3, tipo_union):\n","    caract_1 = pd.read_csv(path_caract_1, index_col=0, header=0)\n","    caract_2 = pd.read_csv(path_caract_2, index_col=0, header=0)\n","    caract_3 = pd.read_csv(path_caract_3, index_col=0, header=0)\n","\n","    #Concatenamos las características\n","    if tipo_union == \"outer\":\n","        caract_merged = pd.merge(caract_1, caract_2, left_index=True, right_index=True, how=\"outer\")\n","        caract = pd.merge(caract_merged, caract_3, left_index=True, right_index=True, how=\"outer\")\n","    elif tipo_union == \"inner\":\n","        caract_merged = pd.merge(caract_1, caract_2, left_index=True, right_index=True, how=\"inner\")\n","        caract = pd.merge(caract_merged, caract_3, left_index=True, right_index=True, how=\"inner\")\n","    caract.fillna(caract.mean(), inplace=True)\n","    return caract\n","\n","def extraeDosCaracteristicas(es_clinica, path_caract_1, path_caract_2, tipo_union):\n","    caract_1 = pd.read_csv(path_caract_1, index_col=0, header=0)\n","    caract_2 = pd.read_csv(path_caract_2, index_col=0, header=0)\n","\n","    #Concatenamos las características\n","    if tipo_union == \"outer\":\n","        caract = pd.merge(caract_1, caract_2, left_index=True, right_index=True, how=\"outer\")\n","    elif tipo_union == \"inner\":\n","        caract = pd.merge(caract_1, caract_2, left_index=True, right_index=True, how=\"inner\")\n","    caract.fillna(caract.mean(), inplace=True)\n","    if not es_clinica:\n","        path_caract_clinicas = path_caract_clinicas = os.path.join(DATASET_FOLDER, 'Caracteristicas_extraidas/datos_clinicos.csv')\n","        caract_clinicas = pd.read_csv(path_caract_clinicas, index_col=0, header=0)\n","        survival_status_col = caract_clinicas['Survival Status | Alive']\n","        df_survival = survival_status_col.to_frame(name='Survival Status | Alive')\n","        caract = pd.merge(caract, df_survival, left_index=True, right_index=True, how=\"inner\")\n","    return caract\n","\n","def extraeUnaCaracteristica(es_clinica, path_caract, tipo_union):\n","    caract = pd.read_csv(path_caract, index_col=0, header=0)\n","    if not es_clinica:\n","        path_caract_clinicas = os.path.join(DATASET_FOLDER, 'Caracteristicas_extraidas/datos_clinicos.csv')\n","        caract_clinicas = pd.read_csv(path_caract_clinicas, index_col=0, header=0)\n","        survival_status_col = caract_clinicas['Survival Status | Alive']\n","        df_survival = survival_status_col.to_frame(name='Survival Status | Alive')\n","        caract = pd.merge(caract, df_survival, left_index=True, right_index=True, how=\"inner\")\n","    return caract\n","\n","def extraeCaractSegunInput(clinicos, genomicos, radiomicos, tipo_union):\n","    path_caract_clinicas = os.path.join(DATASET_FOLDER, 'Caracteristicas_extraidas/datos_clinicos.csv')\n","    path_caract_genomicas = os.path.join(DATASET_FOLDER, 'Caracteristicas_extraidas/datos_genomicos.csv')\n","    path_caract_radiomicas = os.path.join(DATASET_FOLDER, 'Caracteristicas_extraidas/datos_radiomicos.csv')\n","    df_caract = {}\n","    if clinicos and genomicos and radiomicos:\n","        df_caract = extraeCaracteristicasCompletas(path_caract_clinicas, path_caract_genomicas, path_caract_radiomicas, tipo_union)\n","    elif clinicos and genomicos and not radiomicos:\n","        df_caract = extraeDosCaracteristicas(clinicos, path_caract_clinicas, path_caract_genomicas, tipo_union)\n","    elif clinicos and not genomicos and radiomicos:\n","        df_caract = extraeDosCaracteristicas(clinicos, path_caract_clinicas, path_caract_radiomicas, tipo_union)\n","    elif not clinicos and genomicos and radiomicos:\n","        df_caract = extraeDosCaracteristicas(clinicos, path_caract_genomicas, path_caract_radiomicas, tipo_union)\n","    elif clinicos and not genomicos and not radiomicos:\n","        df_caract = extraeUnaCaracteristica(clinicos, path_caract_clinicas, tipo_union)\n","    elif not clinicos and genomicos and not radiomicos:\n","        df_caract = extraeUnaCaracteristica(clinicos, path_caract_genomicas, tipo_union)\n","    elif not clinicos and not genomicos and radiomicos:\n","        df_caract = extraeUnaCaracteristica(clinicos, path_caract_radiomicas, tipo_union)\n","    return df_caract\n","\n","extraeCaractSegunInput(clinicos=False, genomicos=True, radiomicos=True, tipo_union=\"outer\")"],"metadata":{"id":"xHxa16lYl1o_","colab":{"base_uri":"https://localhost:8080/","height":652},"executionInfo":{"status":"ok","timestamp":1697549915400,"user_tz":-180,"elapsed":2099,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}},"outputId":"ccfe3b61-b61b-4e9b-e3b0-a154261bf086"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["               0_x       1_x       2_x       3_x       4_x       5_x  \\\n","AMC-001   0.006026 -0.517859  0.053041 -0.029676 -0.051478 -0.169131   \n","AMC-002   0.006026 -0.517859  0.053041 -0.029676 -0.051478 -0.169131   \n","AMC-003   0.006026 -0.517859  0.053041 -0.029676 -0.051478 -0.169131   \n","AMC-004   0.006026 -0.517859  0.053041 -0.029676 -0.051478 -0.169131   \n","AMC-005   0.006026 -0.517859  0.053041 -0.029676 -0.051478 -0.169131   \n","...            ...       ...       ...       ...       ...       ...   \n","R01-156   7.025757 -5.931159 -3.100637  9.199866  0.013380  0.004615   \n","R01-157   4.181196 -5.879165 -1.256348  6.707151 -0.162189  5.030562   \n","R01-158  14.903090 -7.677206  0.473159  8.042454 -0.167521  0.324751   \n","R01-159  -8.692994 -1.580766 -3.731303  2.604348  8.956873 -0.208848   \n","R01-160  -3.307310 -5.305379  2.262277  1.678871 -2.537761  3.562042   \n","\n","              6_x       7_x       8_x       9_x  ...        68_y         69_y  \\\n","AMC-001 -0.009243  0.044800 -0.167539 -0.050045  ...   64.320879  1749.228961   \n","AMC-002 -0.009243  0.044800 -0.167539 -0.050045  ...   51.604286  1501.787473   \n","AMC-003 -0.009243  0.044800 -0.167539 -0.050045  ...   43.422387  1543.026677   \n","AMC-004 -0.009243  0.044800 -0.167539 -0.050045  ...   77.796909   809.017034   \n","AMC-005 -0.009243  0.044800 -0.167539 -0.050045  ...   63.089273  1432.009101   \n","...           ...       ...       ...       ...  ...         ...          ...   \n","R01-156  5.751905 -1.450845 -4.877836 -2.285581  ...  118.870972  1103.112010   \n","R01-157  4.055994  1.790728 -1.541707 -0.804697  ...   12.546504   699.584094   \n","R01-158  6.534695 -2.529601 -5.471935 -3.321318  ...  118.870972  1103.112010   \n","R01-159 -3.691910 -2.855215 -3.791294  2.129137  ...  118.870972  1103.112010   \n","R01-160 -3.873622  2.339911 -0.787351 -0.948550  ...  118.870972  1103.112010   \n","\n","              70_y          71_y      72_y      73_y      74_y        75_y  \\\n","AMC-001  10.028697  18475.412687  0.041298  0.003921  0.374366  619.156225   \n","AMC-002  44.780683  77968.934357  0.031552  0.001218  0.179935  219.652110   \n","AMC-003   9.427991  15069.390102  0.007481  0.001153  0.353348  522.331503   \n","AMC-004   6.160321   5852.996994  0.021878  0.005051  0.456227  322.002381   \n","AMC-005  24.755580  42053.203900  0.018119  0.001701  0.275254  291.661242   \n","...            ...           ...       ...       ...       ...         ...   \n","R01-156  19.171870  26856.320566  0.241052  0.011503  0.379061  353.711469   \n","R01-157  24.575979  18504.161899  0.033553  0.001914  0.222646  130.856728   \n","R01-158  19.171870  26856.320566  0.241052  0.011503  0.379061  353.711469   \n","R01-159  19.171870  26856.320566  0.241052  0.011503  0.379061  353.711469   \n","R01-160  19.171870  26856.320566  0.241052  0.011503  0.379061  353.711469   \n","\n","             76_y  Survival Status | Alive  \n","AMC-001  0.001360                        0  \n","AMC-002  0.000353                        1  \n","AMC-003  0.000607                        1  \n","AMC-004  0.003008                        1  \n","AMC-005  0.000694                        1  \n","...           ...                      ...  \n","R01-156  0.004620                        0  \n","R01-157  0.000803                        1  \n","R01-158  0.004620                        1  \n","R01-159  0.004620                        1  \n","R01-160  0.004620                        1  \n","\n","[190 rows x 198 columns]"],"text/html":["\n","  <div id=\"df-2ac67517-3f3e-4b04-8434-2cb58fbadd26\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0_x</th>\n","      <th>1_x</th>\n","      <th>2_x</th>\n","      <th>3_x</th>\n","      <th>4_x</th>\n","      <th>5_x</th>\n","      <th>6_x</th>\n","      <th>7_x</th>\n","      <th>8_x</th>\n","      <th>9_x</th>\n","      <th>...</th>\n","      <th>68_y</th>\n","      <th>69_y</th>\n","      <th>70_y</th>\n","      <th>71_y</th>\n","      <th>72_y</th>\n","      <th>73_y</th>\n","      <th>74_y</th>\n","      <th>75_y</th>\n","      <th>76_y</th>\n","      <th>Survival Status | Alive</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>AMC-001</th>\n","      <td>0.006026</td>\n","      <td>-0.517859</td>\n","      <td>0.053041</td>\n","      <td>-0.029676</td>\n","      <td>-0.051478</td>\n","      <td>-0.169131</td>\n","      <td>-0.009243</td>\n","      <td>0.044800</td>\n","      <td>-0.167539</td>\n","      <td>-0.050045</td>\n","      <td>...</td>\n","      <td>64.320879</td>\n","      <td>1749.228961</td>\n","      <td>10.028697</td>\n","      <td>18475.412687</td>\n","      <td>0.041298</td>\n","      <td>0.003921</td>\n","      <td>0.374366</td>\n","      <td>619.156225</td>\n","      <td>0.001360</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>AMC-002</th>\n","      <td>0.006026</td>\n","      <td>-0.517859</td>\n","      <td>0.053041</td>\n","      <td>-0.029676</td>\n","      <td>-0.051478</td>\n","      <td>-0.169131</td>\n","      <td>-0.009243</td>\n","      <td>0.044800</td>\n","      <td>-0.167539</td>\n","      <td>-0.050045</td>\n","      <td>...</td>\n","      <td>51.604286</td>\n","      <td>1501.787473</td>\n","      <td>44.780683</td>\n","      <td>77968.934357</td>\n","      <td>0.031552</td>\n","      <td>0.001218</td>\n","      <td>0.179935</td>\n","      <td>219.652110</td>\n","      <td>0.000353</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>AMC-003</th>\n","      <td>0.006026</td>\n","      <td>-0.517859</td>\n","      <td>0.053041</td>\n","      <td>-0.029676</td>\n","      <td>-0.051478</td>\n","      <td>-0.169131</td>\n","      <td>-0.009243</td>\n","      <td>0.044800</td>\n","      <td>-0.167539</td>\n","      <td>-0.050045</td>\n","      <td>...</td>\n","      <td>43.422387</td>\n","      <td>1543.026677</td>\n","      <td>9.427991</td>\n","      <td>15069.390102</td>\n","      <td>0.007481</td>\n","      <td>0.001153</td>\n","      <td>0.353348</td>\n","      <td>522.331503</td>\n","      <td>0.000607</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>AMC-004</th>\n","      <td>0.006026</td>\n","      <td>-0.517859</td>\n","      <td>0.053041</td>\n","      <td>-0.029676</td>\n","      <td>-0.051478</td>\n","      <td>-0.169131</td>\n","      <td>-0.009243</td>\n","      <td>0.044800</td>\n","      <td>-0.167539</td>\n","      <td>-0.050045</td>\n","      <td>...</td>\n","      <td>77.796909</td>\n","      <td>809.017034</td>\n","      <td>6.160321</td>\n","      <td>5852.996994</td>\n","      <td>0.021878</td>\n","      <td>0.005051</td>\n","      <td>0.456227</td>\n","      <td>322.002381</td>\n","      <td>0.003008</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>AMC-005</th>\n","      <td>0.006026</td>\n","      <td>-0.517859</td>\n","      <td>0.053041</td>\n","      <td>-0.029676</td>\n","      <td>-0.051478</td>\n","      <td>-0.169131</td>\n","      <td>-0.009243</td>\n","      <td>0.044800</td>\n","      <td>-0.167539</td>\n","      <td>-0.050045</td>\n","      <td>...</td>\n","      <td>63.089273</td>\n","      <td>1432.009101</td>\n","      <td>24.755580</td>\n","      <td>42053.203900</td>\n","      <td>0.018119</td>\n","      <td>0.001701</td>\n","      <td>0.275254</td>\n","      <td>291.661242</td>\n","      <td>0.000694</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>R01-156</th>\n","      <td>7.025757</td>\n","      <td>-5.931159</td>\n","      <td>-3.100637</td>\n","      <td>9.199866</td>\n","      <td>0.013380</td>\n","      <td>0.004615</td>\n","      <td>5.751905</td>\n","      <td>-1.450845</td>\n","      <td>-4.877836</td>\n","      <td>-2.285581</td>\n","      <td>...</td>\n","      <td>118.870972</td>\n","      <td>1103.112010</td>\n","      <td>19.171870</td>\n","      <td>26856.320566</td>\n","      <td>0.241052</td>\n","      <td>0.011503</td>\n","      <td>0.379061</td>\n","      <td>353.711469</td>\n","      <td>0.004620</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>R01-157</th>\n","      <td>4.181196</td>\n","      <td>-5.879165</td>\n","      <td>-1.256348</td>\n","      <td>6.707151</td>\n","      <td>-0.162189</td>\n","      <td>5.030562</td>\n","      <td>4.055994</td>\n","      <td>1.790728</td>\n","      <td>-1.541707</td>\n","      <td>-0.804697</td>\n","      <td>...</td>\n","      <td>12.546504</td>\n","      <td>699.584094</td>\n","      <td>24.575979</td>\n","      <td>18504.161899</td>\n","      <td>0.033553</td>\n","      <td>0.001914</td>\n","      <td>0.222646</td>\n","      <td>130.856728</td>\n","      <td>0.000803</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>R01-158</th>\n","      <td>14.903090</td>\n","      <td>-7.677206</td>\n","      <td>0.473159</td>\n","      <td>8.042454</td>\n","      <td>-0.167521</td>\n","      <td>0.324751</td>\n","      <td>6.534695</td>\n","      <td>-2.529601</td>\n","      <td>-5.471935</td>\n","      <td>-3.321318</td>\n","      <td>...</td>\n","      <td>118.870972</td>\n","      <td>1103.112010</td>\n","      <td>19.171870</td>\n","      <td>26856.320566</td>\n","      <td>0.241052</td>\n","      <td>0.011503</td>\n","      <td>0.379061</td>\n","      <td>353.711469</td>\n","      <td>0.004620</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>R01-159</th>\n","      <td>-8.692994</td>\n","      <td>-1.580766</td>\n","      <td>-3.731303</td>\n","      <td>2.604348</td>\n","      <td>8.956873</td>\n","      <td>-0.208848</td>\n","      <td>-3.691910</td>\n","      <td>-2.855215</td>\n","      <td>-3.791294</td>\n","      <td>2.129137</td>\n","      <td>...</td>\n","      <td>118.870972</td>\n","      <td>1103.112010</td>\n","      <td>19.171870</td>\n","      <td>26856.320566</td>\n","      <td>0.241052</td>\n","      <td>0.011503</td>\n","      <td>0.379061</td>\n","      <td>353.711469</td>\n","      <td>0.004620</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>R01-160</th>\n","      <td>-3.307310</td>\n","      <td>-5.305379</td>\n","      <td>2.262277</td>\n","      <td>1.678871</td>\n","      <td>-2.537761</td>\n","      <td>3.562042</td>\n","      <td>-3.873622</td>\n","      <td>2.339911</td>\n","      <td>-0.787351</td>\n","      <td>-0.948550</td>\n","      <td>...</td>\n","      <td>118.870972</td>\n","      <td>1103.112010</td>\n","      <td>19.171870</td>\n","      <td>26856.320566</td>\n","      <td>0.241052</td>\n","      <td>0.011503</td>\n","      <td>0.379061</td>\n","      <td>353.711469</td>\n","      <td>0.004620</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>190 rows × 198 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ac67517-3f3e-4b04-8434-2cb58fbadd26')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2ac67517-3f3e-4b04-8434-2cb58fbadd26 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2ac67517-3f3e-4b04-8434-2cb58fbadd26');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c65efcc8-5128-4d4b-acb8-75e0cc699be9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c65efcc8-5128-4d4b-acb8-75e0cc699be9')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c65efcc8-5128-4d4b-acb8-75e0cc699be9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# 5. Implementación modelo"],"metadata":{"id":"daBXB34ifIgj"}},{"cell_type":"markdown","source":["Probando con modelo propio"],"metadata":{"id":"AoCb9ad1ymaC"}},{"cell_type":"code","source":["def creaModeloMultimodalComplejo(x_train):\n","    model = Sequential()\n","    model.add(Dense(512,input_dim = x_train.shape[1],activation=\"relu\"))\n","    model.add(Dense(512,activation=\"relu\"))\n","    model.add(Dense(256,activation=\"relu\"))\n","    model.add(Dense(64, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1,activation = \"sigmoid\"))\n","\n","    return model\n","\n","def creaModeloMultimodalSimple(x_train):\n","    model = Sequential()\n","    model.add(Dense(64,input_dim = x_train.shape[1],activation=\"relu\"))\n","    model.add(Dense(32, activation='relu'))\n","    model.add(Dropout(0.2))\n","    model.add(Dense(1, activation='sigmoid'))\n","\n","    return model\n","\n","def mostrarCurvaAprendizaje(H, num_epocas):\n","    plt.style.use(\"ggplot\")\n","    plt.figure()\n","    plt.plot(np.arange(5, num_epocas), H.history[\"loss\"][4:79], label=\"train_loss\")\n","    plt.plot(np.arange(5, num_epocas), H.history[\"val_loss\"][4:79], label=\"val_loss\")\n","    plt.plot(np.arange(5, num_epocas), H.history[\"accuracy\"][4:79], label=\"train_acc\")\n","    plt.plot(np.arange(5, num_epocas), H.history[\"val_accuracy\"][4:79], label=\"val_acc\")\n","    plt.title(\"Training Loss and Accuracy\")\n","    plt.xlabel(\"Epoch #\")\n","    plt.ylabel(\"Loss/Accuracy\")\n","    plt.legend()\n","    plt.show()\n","\n","def prediceSupervivenciaParaModelo(modelo, x_train, x_test, y_train):\n","    num_epocas = 80\n","    modelo.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","    H = modelo.fit(x_train, y_train, epochs=num_epocas, batch_size=16, validation_split=0.2, verbose=False)\n","    predictions = modelo.predict(x_test)\n","    #mostrarHistograma(H, num_epocas)\n","\n","    return predictions\n","\n","def obtenMetricas(y_test, y_pred):\n","    binary_predictions = (y_pred > 0.5).astype(int)\n","\n","    accuracy = accuracy_score(y_test, binary_predictions)\n","    precision = precision_score(y_test, binary_predictions)\n","    recall = recall_score(y_test, binary_predictions)\n","    f1 = f1_score(y_test, binary_predictions)\n","    print('Métricas: {')\n","    print('     accuracy:  %.4f' % accuracy)\n","    print('     precision: %.4f' % precision)\n","    print('     recall: %.4f' % recall)\n","    print('     f1:   %.4f' % f1)\n","    print('}')\n","\n","def cargaCaracteristicasYPrediceSegunInput(clinicos, genomicos, radiomicos, tipo_union, texto_datos, texto_union):\n","    df_caract = extraeCaractSegunInput(clinicos, genomicos, radiomicos, tipo_union)\n","    df_caract = df_caract._get_numeric_data()\n","\n","    x = df_caract.values.astype(int)\n","    y = df_caract['Survival Status | Alive'].values.astype(int)\n","    #print(\"Y shape: \", y.shape)\n","\n","    predecirSupervivencia(x, y, x.shape, texto_datos, texto_union)\n","\n","def printTextos(texto_datos, texto_union):\n","    print(texto_datos)\n","    print(texto_union)\n","\n","def predecirSupervivencia(x, y, x_shape, texto_datos, texto_union):\n","\tx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.15)\n","\tx_train_val, x_test_val, y_train_val, y_test_val = train_test_split(x_train, y_train, test_size = 0.15)\n","\t#print(\"X_train shape:\", x_train.shape)\n","\t#print(\"y_train shape:\", y_train.shape)\n","\n","\tconjunto_modelos = {}\n","\tconjunto_modelos[\"Red neuronal propia\"] = creaModeloMultimodalComplejo(x_train)\n","\tplot_model(conjunto_modelos[\"Red neuronal propia\"], show_shapes=True, to_file='modelo_complejo_estructura.png')\n","\n","\tconjunto_modelos[\"Clasificador MLP\"] = MLPClassifier(solver='adam', random_state=42)\n","\tconjunto_modelos[\"Regresión logística\"] = LogisticRegression(random_state=42)\n","\tconjunto_modelos[\"K vecinos\"] = KNeighborsClassifier(n_neighbors=6,  metric=\"euclidean\")\n","\n","\tfor modelo in conjunto_modelos:\n","\n","\t\tprint(\"-----------------------\")\n","\t\tprintTextos(texto_datos, texto_union)\n","\t\tprint(\"Tamaño conjunto de datos: \", x_shape)\n","\t\tprint(\"Modelo:  \" + modelo)\n","\t\tif modelo == \"Red neuronal propia\":\n","\t\t\ty_pred = prediceSupervivenciaParaModelo(conjunto_modelos[modelo], x_train, x_test, y_train)\n","\t\t\tobtenMetricas(y_test, y_pred)\n","\t\telif modelo == \"K vecinos\":\n","\t\t\tprint('Métricas: {')\n","\t\t\tprecision = cross_val_score(conjunto_modelos[modelo], x_train, y_train, cv=10, scoring='precision')\n","\t\t\tprint('     precision:  %.4f' % precision.mean())\n","\t\t\taccuracy = cross_val_score(conjunto_modelos[modelo], x_train, y_train, cv=10, scoring='accuracy')\n","\t\t\tprint('     accuracy:  %.4f' % accuracy.mean())\n","\t\t\trecall = cross_val_score(conjunto_modelos[modelo], x_train, y_train, cv=10, scoring='recall')\n","\t\t\tprint('     recall:  %.4f' % recall.mean())\n","\t\t\tf1 = cross_val_score(conjunto_modelos[modelo], x_train, y_train, cv=10, scoring='f1')\n","\t\t\tprint('     f1:  %.4f' % f1.mean())\n","\t\t\tprint('}')\n","\t\telse:\n","\t\t\tconjunto_modelos[modelo] = conjunto_modelos[modelo].fit(x_train, y_train)\n","\t\t\ty_pred = conjunto_modelos[modelo].predict(x_test)\n","\t\t\tobtenMetricas(y_test, y_pred)\n","\t\tprint(\"-----------------------\\n\")\n","\n","def muestraTodasLasPrediccionesPosibles():\n","    tipos_union = {\"outer\", \"inner\"}\n","    #Solo datos clínicos\n","    texto_union = \"Tipo de unión de datos: ninguna\"\n","    texto_datos = \"Tipos de datos: datos clínicos\"\n","    cargaCaracteristicasYPrediceSegunInput(clinicos=True, genomicos=False, radiomicos=False, tipo_union=None, texto_datos=texto_datos, texto_union=texto_union)\n","\n","    #Solo datos genómicos\n","    texto_union = \"Tipo de unión de datos: ninguna\"\n","    texto_datos = \"Tipos de datos usados: datos genómicos\"\n","    cargaCaracteristicasYPrediceSegunInput(clinicos=False, genomicos=True, radiomicos=False, tipo_union=None, texto_datos=texto_datos, texto_union=texto_union)\n","\n","    #Solo datos radiómicos\n","    texto_union = \"Tipo de unión de datos: ninguna\"\n","    texto_datos = \"Tipos de datos usados: datos radiómicos\"\n","    cargaCaracteristicasYPrediceSegunInput(clinicos=False, genomicos=False, radiomicos=True, tipo_union=None, texto_datos=texto_datos, texto_union=texto_union)\n","\n","    for union in tipos_union:\n","        texto_union = \"Tipo de unión de datos: \" + union\n","        #Datos clínicos y genómicos\n","        texto_datos = \"Tipos de datos usados: clínicos y genómicos\"\n","        cargaCaracteristicasYPrediceSegunInput(clinicos=True, genomicos=True, radiomicos=False, tipo_union=union, texto_datos=texto_datos, texto_union=texto_union)\n","\n","        #Datos clínicos y radiómicos\n","        texto_union = \"Tipo de unión de datos: \" + union\n","        texto_datos = \"Tipos de datos usados: clínicos y radiómicos\"\n","        cargaCaracteristicasYPrediceSegunInput(clinicos=True, genomicos=False, radiomicos=True, tipo_union=union, texto_datos=texto_datos, texto_union=texto_union)\n","\n","        #Datos genómicos y radiómicos\n","        texto_union = \"Tipo de unión de datos: \" + union\n","        texto_datos = \"Tipos de datos usados: genómicos y radiómicos\"\n","        cargaCaracteristicasYPrediceSegunInput(clinicos=False, genomicos=True, radiomicos=True, tipo_union=union, texto_datos=texto_datos, texto_union=texto_union)\n","\n","        #Todos los datos: clínicos, genómicos y radiómicos\n","        texto_union = \"Tipo de unión de datos: \" + union\n","        texto_datos = \"Tipos de datos usados: clínicos, genómicos y radiómicos\"\n","        cargaCaracteristicasYPrediceSegunInput(clinicos=True, genomicos=True, radiomicos=True, tipo_union=union, texto_datos=texto_datos, texto_union=texto_union)\n","\n","muestraTodasLasPrediccionesPosibles()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YozrI2kXfMvv","executionInfo":{"status":"ok","timestamp":1697552216703,"user_tz":-180,"elapsed":74214,"user":{"displayName":"Roge Sansaloni Sanjuan","userId":"15901799583746821872"}},"outputId":"cb1aae41-380f-482b-a4af-6a7bcfc997b9"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["-----------------------\n","Tipos de datos: datos clínicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (211, 79)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 89ms/step\n","Métricas: {\n","     accuracy:  1.0000\n","     precision: 1.0000\n","     recall: 1.0000\n","     f1:   1.0000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos: datos clínicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (211, 79)\n","Modelo:  Clasificador MLP\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Métricas: {\n","     accuracy:  0.7500\n","     precision: 0.7619\n","     recall: 0.8421\n","     f1:   0.8000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos: datos clínicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (211, 79)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  1.0000\n","     precision: 1.0000\n","     recall: 1.0000\n","     f1:   1.0000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos: datos clínicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (211, 79)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.8560\n","     accuracy:  0.8657\n","     recall:  0.9846\n","     f1:  0.9146\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos genómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (110, 121)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 63ms/step\n","Métricas: {\n","     accuracy:  0.5294\n","     precision: 0.5000\n","     recall: 1.0000\n","     f1:   0.6667\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos genómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (110, 121)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.4118\n","     precision: 0.4286\n","     recall: 0.7500\n","     f1:   0.5455\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos genómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (110, 121)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.6471\n","     precision: 0.5714\n","     recall: 1.0000\n","     f1:   0.7273\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos genómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (110, 121)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.6996\n","     accuracy:  0.5489\n","     recall:  0.6286\n","     f1:  0.6526\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos radiómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (135, 78)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 61ms/step\n","Métricas: {\n","     accuracy:  0.8095\n","     precision: 0.8095\n","     recall: 1.0000\n","     f1:   0.8947\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos radiómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (135, 78)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.1905\n","     precision: 0.0000\n","     recall: 0.0000\n","     f1:   0.0000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos radiómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (135, 78)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.8095\n","     precision: 0.8095\n","     recall: 1.0000\n","     f1:   0.8947\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: datos radiómicos\n","Tipo de unión de datos: ninguna\n","Tamaño conjunto de datos:  (135, 78)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.6947\n","     accuracy:  0.5705\n","     recall:  0.6607\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["     f1:  0.6715\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (110, 199)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 64ms/step\n","Métricas: {\n","     accuracy:  0.7059\n","     precision: 0.6667\n","     recall: 1.0000\n","     f1:   0.8000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (110, 199)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.5882\n","     precision: 0.6154\n","     recall: 0.8000\n","     f1:   0.6957\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (110, 199)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.6471\n","     precision: 0.6429\n","     recall: 0.9000\n","     f1:   0.7500\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (110, 199)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.7460\n","     accuracy:  0.5811\n","     recall:  0.5976\n","     f1:  0.6563\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (135, 156)\n","Modelo:  Red neuronal propia\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79b820126680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 60ms/step\n","Métricas: {\n","     accuracy:  0.6667\n","     precision: 0.6667\n","     recall: 1.0000\n","     f1:   0.8000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (135, 156)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.6190\n","     precision: 0.6875\n","     recall: 0.7857\n","     f1:   0.7333\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (135, 156)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.6667\n","     precision: 0.6667\n","     recall: 1.0000\n","     f1:   0.8000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (135, 156)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.6928\n","     accuracy:  0.5848\n","     recall:  0.7375\n","     f1:  0.7062\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 198)\n","Modelo:  Red neuronal propia\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79b7e81fa4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"]},{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 61ms/step\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Métricas: {\n","     accuracy:  0.0000\n","     precision: 0.0000\n","     recall: 0.0000\n","     f1:   0.0000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 198)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.8889\n","     precision: 0.8889\n","     recall: 1.0000\n","     f1:   0.9412\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 198)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.7778\n","     precision: 0.8750\n","     recall: 0.8750\n","     f1:   0.8750\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 198)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.3167\n","     accuracy:  0.4300\n","     recall:  0.3167\n","     f1:  0.3038\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 276)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 62ms/step\n","Métricas: {\n","     accuracy:  0.6667\n","     precision: 1.0000\n","     recall: 0.4000\n","     f1:   0.5714\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 276)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.5556\n","     precision: 0.5556\n","     recall: 1.0000\n","     f1:   0.7143\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 276)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.5556\n","     precision: 0.5556\n","     recall: 1.0000\n","     f1:   0.7143\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: inner\n","Tamaño conjunto de datos:  (55, 276)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.6167\n","     accuracy:  0.5450\n","     recall:  0.5667\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["     f1:  0.5605\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 199)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 60ms/step\n","Métricas: {\n","     accuracy:  0.7812\n","     precision: 0.8182\n","     recall: 0.8571\n","     f1:   0.8372\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 199)\n","Modelo:  Clasificador MLP\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Métricas: {\n","     accuracy:  0.6875\n","     precision: 0.7619\n","     recall: 0.7619\n","     f1:   0.7619\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 199)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.8750\n","     precision: 0.9048\n","     recall: 0.9048\n","     f1:   0.9048\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y genómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 199)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.8362\n","     accuracy:  0.8039\n","     recall:  0.9051\n","     f1:  0.8680\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 156)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 59ms/step\n","Métricas: {\n","     accuracy:  0.8125\n","     precision: 0.8125\n","     recall: 1.0000\n","     f1:   0.8966\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 156)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.4375\n","     precision: 1.0000\n","     recall: 0.3077\n","     f1:   0.4706\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 156)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.7500\n","     precision: 0.8000\n","     recall: 0.9231\n","     f1:   0.8571\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 156)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.6987\n","     accuracy:  0.6294\n","     recall:  0.7776\n","     f1:  0.7261\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (190, 198)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 58ms/step\n","Métricas: {\n","     accuracy:  0.1724\n","     precision: 0.0000\n","     recall: 0.0000\n","     f1:   0.0000\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (190, 198)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.8276\n","     precision: 0.8276\n","     recall: 1.0000\n","     f1:   0.9057\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (190, 198)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.8276\n","     precision: 0.8276\n","     recall: 1.0000\n","     f1:   0.9057\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (190, 198)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.6181\n","     accuracy:  0.4967\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["     recall:  0.6527\n","     f1:  0.6194\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 276)\n","Modelo:  Red neuronal propia\n","1/1 [==============================] - 0s 60ms/step\n","Métricas: {\n","     accuracy:  0.5938\n","     precision: 0.6129\n","     recall: 0.9500\n","     f1:   0.7451\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 276)\n","Modelo:  Clasificador MLP\n","Métricas: {\n","     accuracy:  0.3750\n","     precision: 0.5000\n","     recall: 0.1000\n","     f1:   0.1667\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 276)\n","Modelo:  Regresión logística\n","Métricas: {\n","     accuracy:  0.6250\n","     precision: 0.6250\n","     recall: 1.0000\n","     f1:   0.7692\n","}\n","-----------------------\n","\n","-----------------------\n","Tipos de datos usados: clínicos, genómicos y radiómicos\n","Tipo de unión de datos: outer\n","Tamaño conjunto de datos:  (211, 276)\n","Modelo:  K vecinos\n","Métricas: {\n","     precision:  0.7112\n","     accuracy:  0.6193\n","     recall:  0.7788\n","     f1:  0.7309\n","}\n","-----------------------\n","\n"]}]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","collapsed_sections":["B7BjOeaZGG8z"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}